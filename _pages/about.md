---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<div style="margin-bottom: 20px;">
  I'm a master student in <strong>Robotics, Cognition, Intelligence (RCI)</strong> at Technical University of Munich (TUM). I finished my master thesis in the Center for Information and Language Processing (CIS), LMU in the group of <a href="https://www.cis.uni-muenchen.de/personen/professoren/schuetze/index.html">Prof. Dr. Hinrich Schütze</a>, which focus on <em>Large Language Model</em> and <em>Mechanistic Interpretability (MI)</em>. My research interests include interpretability for large language model, and multilingual natural language processing. I'm also interested in reinforcement learning and knowledge editing for language model.
</div>

<div style="margin-bottom: 20px;">
  Before that, I obtained my bachelor's degree in Mechanical Engineering at <a href="https://www.seu.edu.cn/english/">Southeast University</a>, Nanjing, China.
</div>

## <i class="fas fa-flask" style="color: #0366d6;"></i> Research Interests

<ul style="margin-bottom: 20px;">
  <li><strong>Multilingual NLP</strong></li>
  <li><strong>Interpretability for Large Language Models</strong></li>
  <li><strong>Knowledge-Grounded Text Generation</strong></li>
</ul>

## <i class="fas fa-newspaper" style="color: #0366d6;"></i> News

<div style="background-color: #f6f8fa; border-left: 4px solid #0366d6; padding: 12px 15px; margin-bottom: 20px;">
  <strong>Feb. 2025</strong> - The preprint of my master thesis: "On Relation-Specific Neurons in Large Language Models" is available on <a href="https://arxiv.org/abs/2502.17355">arXiv</a>!
</div>

## <i class="fas fa-project-diagram" style="color: #0366d6;"></i> Previous Projects

<div style="border-radius: 4px; padding: 15px 20px; margin-bottom: 25px; box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);">
  <h3 style="margin-top: 0; color: #24292e; border-bottom: 1px solid #eaecef; padding-bottom: 10px;">Detecting Multi-Lingual Relation Specific Neurons in LLMs</h3>
  <p style="color: #586069; margin-top: 0;"><i class="fas fa-university"></i> Ludwig-Maximilians-Universität | <i class="fas fa-calendar-alt"></i> 07.2024 - 02.2025 | <em>Master Thesis</em></p>
  
  <p><em>Large Language Models, Mechanistic Interpretability, Multilingual NLP</em></p>
  
  <ul>
    <li><strong>Identification and characterization</strong> of neurons that store explicit knowledge about semantic relations, with a particular focus on multilingual contexts.</li>
    <li><strong>Development of a methodological pipeline</strong> for localizing relation-specific neurons using a tailored dataset and validation by controlled generation experiments.</li>
    <li><strong>Detailed analysis of the neuronal activation patterns</strong> in the Llama-2 (7B & 13B) model to examine their distribution and inherent properties.</li>
    <li><strong>Achievements</strong>: Creation of a comprehensive <strong>relation-specific neuron set</strong> for Llama-2 model and a planned <strong>submission to a top NLP conference</strong>.</li>
  </ul>
</div>

<div style="border-radius: 4px; padding: 15px 20px; margin-bottom: 25px; box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);">
  <h3 style="margin-top: 0; color: #24292e; border-bottom: 1px solid #eaecef; padding-bottom: 10px;">LLM-based Chat-with-File Chatbot Development</h3>
  <p style="color: #586069; margin-top: 0;"><i class="fas fa-university"></i> Technical University of Munich | <i class="fas fa-calendar-alt"></i> 08.2023 - 04.2024 | <em>HiWi Project</em></p>
  
  <p><em>Large Language Models, LangChain, RAG, Streamlit</em></p>
  
  <ul>
    <li><strong>Designed and implemented</strong> an intelligent chatbot system capable of interacting with user-uploaded files, leveraging Retrieval-Augmented Generation (RAG) and LangChain.</li>
    <li><strong>Developed a robust RAG pipeline</strong> encompassing document chunking, embedding, retrieval optimization, and a user-friendly interface built with <em>Streamlit</em>.</li>
    <li><strong>Achievements</strong>: Automated document processing, significantly enhancing retrieval efficiency and reducing response time from <strong>20s to 3s</strong>.</li>
  </ul>
</div>

<div style="border-radius: 4px; padding: 15px 20px; margin-bottom: 25px; box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);">
  <h3 style="margin-top: 0; color: #24292e; border-bottom: 1px solid #eaecef; padding-bottom: 10px;">LLM-assisted Construction of a Corpus of Sustainable Product Reviews</h3>
  <p style="color: #586069; margin-top: 0;"><i class="fas fa-university"></i> Technical University of Munich | <i class="fas fa-calendar-alt"></i> 09.2023 - 04.2024 | <em>Guided Research, Grade: 1.3</em></p>
  
  <p><em>Large Language Models, Corpus Creation, LangChain</em></p>
  
  <ul>
    <li><strong>Development of a scalable, automated pipeline</strong> for creating a domain-specific corpus of sustainable product reviews.</li>
    <li><strong>Implementation and optimization</strong> of data collection and processing methods using <em>OpenAI</em> API and <em>LangChain</em>.</li>
    <li><strong>Systematic evaluation and refinement</strong> of prompting techniques (zero-shot, few-shot, chain-of-thought) to maximize the quality and consistency of the annotated data.</li>
    <li><strong>Achievements</strong>: Increased LLM-assisted annotation accuracy from 20% to 95%, significantly improving the efficiency and reliability of automated data generation.</li>
  </ul>
</div>

